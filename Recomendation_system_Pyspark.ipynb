{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIY8cXPfsrlU",
        "outputId": "d502274c-f94e-46cc-e216-94d305506737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNUpo12Ss0Ik",
        "outputId": "41237e74-acfb-4abe-853d-69f077d0a471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=544ccb6c1cf1eb1893563e3ca71fac214d71d3634fa066f58fc134aded59c7e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|      2|   3.5|1112486027|\n",
            "|     1|     29|   3.5|1112484676|\n",
            "|     1|     32|   3.5|1112484819|\n",
            "|     1|     47|   3.5|1112484727|\n",
            "|     1|     50|   3.5|1112484580|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.mllib.recommendation import Rating\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, RankingEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Recommender system\")\\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# movies = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"/content/drive/MyDrive/ratings.csv\", header=True, inferSchema=True)\n",
        "# movies.show(5)\n",
        "ratings.show(5)\n",
        "# movie_ratings = ratings.join(movies, [\"movieId\"], \"inner\")\n",
        "# movie_ratings.show(5)\n",
        "# movie_ratings = movie_ratings.filter(col(\"userId\").isNotNull())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJLFUbP0tqVe",
        "outputId": "7f3efd2d-e619-42d4-dd2d-50163d3a3bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    223|   4.0|1112485573|\n",
            "|     1|    589|   3.5|1112485557|\n",
            "|     1|    653|   3.0|1094785691|\n",
            "|     1|   1090|   4.0|1112485453|\n",
            "|     1|   1215|   4.0|1094786082|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampled_ratings = ratings.sample(fraction=0.2, seed=42)\n",
        "sampled_ratings.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9XfPIr5t4U0",
        "outputId": "04c7dca2-de03-4b89-f70d-d93415964179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4004253\n"
          ]
        }
      ],
      "source": [
        "print(sampled_ratings.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcVKG5Nj4o6O"
      },
      "outputs": [],
      "source": [
        "#df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hWz8whvvVqo7",
        "outputId": "f9ed1b98-76c4-44ed-ffc0-079fb040a33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+-----------+\n",
            "|userId|movieId|rating| timestamp| prediction|\n",
            "+------+-------+------+----------+-----------+\n",
            "|   148|   1777|   3.0|1018967190|0.075332925|\n",
            "|   148|   4366|   3.0|1018966761|0.008367139|\n",
            "|   463|     11|   4.0| 833466239| 0.29597232|\n",
            "|   463|    161|   4.0| 833465881|  0.4959344|\n",
            "|   463|    207|   4.0| 833466874| 0.12944262|\n",
            "+------+-------+------+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "RMSE: 3.538607774732653\n",
            "MSE: 12.521744983398378\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Assuming you have the required imports\n",
        "\n",
        "# ...\n",
        "\n",
        "# Your data splitting\n",
        "(train_data, test_data) = sampled_ratings.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "# ALS model configuration\n",
        "als = ALS(\n",
        "    maxIter=10,\n",
        "    regParam=0.01,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    implicitPrefs=True,  # Change to False if your data is explicit feedback\n",
        "    nonnegative=True\n",
        ")\n",
        "\n",
        "# Parameter grid\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(als.rank, [5,3]) \\\n",
        "    .addGrid(als.regParam, [0.1, 0.01]) \\\n",
        "    .addGrid(als.maxIter, [5]) \\\n",
        "    .build()\n",
        "\n",
        "# Evaluation\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "crossval = CrossValidator(\n",
        "    estimator=als,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3\n",
        ")\n",
        "\n",
        "# Model fitting\n",
        "ALSModel = crossval.fit(train_data)\n",
        "bestModel = ALSModel.bestModel\n",
        "\n",
        "# Predictions\n",
        "predictions = bestModel.transform(test_data)\n",
        "predictions.show(5)\n",
        "\n",
        "# Evaluation metrics\n",
        "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
        "mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"MSE: {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmBUoC4WvRjM",
        "outputId": "f3416b24-ea37-48b4-fe8b-e4fd7d655070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.012295327184645705\n"
          ]
        }
      ],
      "source": [
        "from pyspark.mllib.evaluation import RankingMetrics\n",
        "from pyspark.sql.functions import col, collect_list\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "userRecs = bestModel.recommendForAllUsers(100)\n",
        "\n",
        "user_ground_truth = test_data.groupby('userId').agg(collect_list('movieId').alias('ground_truth_items'))\n",
        "user_train_items = train_data.groupby('userId').agg(collect_list('movieId').alias('train_items'))\n",
        "\n",
        "\n",
        "user_eval = userRecs.join(user_ground_truth, on='userId').join(user_train_items, on='userId') \\\n",
        "    .select('userId', 'recommendations.movieId', 'ground_truth_items', 'train_items', 'recommendations.rating')\n",
        "\n",
        "def calculate_precision(predicted, actual):\n",
        "    k_values = range(1, len(actual) + 1)\n",
        "    precision_values = [\n",
        "        len(set(predicted[:k]) & set(actual)) / float(k) for k in k_values\n",
        "    ]\n",
        "    return float(sum(precision_values)) / len(precision_values)\n",
        "\n",
        "calculate_precision_udf = udf(calculate_precision, FloatType())\n",
        "\n",
        "\n",
        "user_eval = user_eval.withColumn(\n",
        "    'precision',\n",
        "    calculate_precision_udf(user_eval['movieId'], user_eval['ground_truth_items'])\n",
        ")\n",
        "\n",
        "# MAP = user_eval.agg({'precision': 'avg'}).collect()[0][0]\n",
        "MAP = user_eval.agg(F.mean('precision')).collect()[0][0]\n",
        "print(f\"MAP: {MAP}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv8AMXB6yfry",
        "outputId": "b7f5d74b-4edc-46ee-b113-aec5cae7ed9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------+--------------------+--------------------+\n",
            "|movieId|         user_rating|movieId2|        user_rating2|          similarity|\n",
            "+-------+--------------------+--------+--------------------+--------------------+\n",
            "|      1|[{309, 4.0}, {413...|       2|[{2487, 2.0}, {26...|0.007491789327389531|\n",
            "|      1|[{309, 4.0}, {413...|       3|[{2350, 3.0}, {46...|0.009125266483879567|\n",
            "|      1|[{309, 4.0}, {413...|       4|[{156, 3.0}, {168...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|       5|[{324, 3.0}, {429...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|       6|[{2082, 3.5}, {20...|0.007502872148281604|\n",
            "|      1|[{309, 4.0}, {413...|       7|[{741, 4.5}, {138...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|       8|[{4494, 4.0}, {76...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|       9|[{2856, 0.5}, {17...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      10|[{159, 3.0}, {557...|0.003378346915809851|\n",
            "|      1|[{309, 4.0}, {413...|      11|[{751, 4.0}, {135...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      12|[{2914, 2.0}, {14...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      13|[{20663, 3.0}, {2...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      14|[{886, 4.0}, {449...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      15|[{5036, 0.5}, {85...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      16|[{2948, 4.5}, {48...|0.008549380611425152|\n",
            "|      1|[{309, 4.0}, {413...|      17|[{1509, 4.0}, {35...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      18|[{1453, 4.0}, {20...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      19|[{1087, 2.0}, {15...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      20|[{3979, 4.0}, {15...|                 0.0|\n",
            "|      1|[{309, 4.0}, {413...|      21|[{158, 4.0}, {368...|                 0.0|\n",
            "+-------+--------------------+--------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, ArrayType, MapType\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import math\n",
        "\n",
        "#(train_data, test_data) = df.randomSplit([0.8, 0.2],seed=123)\n",
        "(train_data, test_data) = sampled_ratings.randomSplit([0.8, 0.2],seed=123)\n",
        "\n",
        "movie_grouped = train_data.groupBy('movieId').agg(\n",
        "    F.collect_list('userId').alias('users'),\n",
        "    F.collect_list('rating').alias('ratings')\n",
        ")\n",
        "movie_ratings_combined = movie_grouped.withColumn(\n",
        "    'user_rating',\n",
        "    F.arrays_zip('users', 'ratings')\n",
        ").select('movieId', 'user_rating')\n",
        "\n",
        "def cosine_similarity(ratings1, ratings2):\n",
        "    rating_dict1 = {r['users']: r['ratings'] for r in ratings1}\n",
        "    rating_dict2 = {r['users']: r['ratings'] for r in ratings2}\n",
        "\n",
        "    common_users = set(rating_dict1.keys()).intersection(rating_dict2.keys())\n",
        "\n",
        "    dot_product = sum(rating_dict1[user] * rating_dict2[user] for user in common_users)\n",
        "    magnitude1 = math.sqrt(sum(rating_dict1[user] ** 2 for user in rating_dict1))\n",
        "    magnitude2 = math.sqrt(sum(rating_dict2[user] ** 2 for user in rating_dict2))\n",
        "\n",
        "    if magnitude1 != 0 and magnitude2 != 0:\n",
        "        return dot_product / (magnitude1 * magnitude2)\n",
        "    else:\n",
        "        return 0.0\n",
        "cosine_similarity_udf = udf(cosine_similarity, DoubleType())\n",
        "\n",
        "movie_pairs_with_similarity = movie_ratings_combined.alias(\"df1\").crossJoin(\n",
        "    movie_ratings_combined.alias(\"df2\").withColumnRenamed(\"movieId\", \"movieId2\").withColumnRenamed(\"user_rating\", \"user_rating2\")\n",
        ").where(\"df1.movieId != movieId2\").withColumn(\n",
        "    \"similarity\",\n",
        "    cosine_similarity_udf(col(\"df1.user_rating\"), col(\"user_rating2\"))\n",
        ")\n",
        "\n",
        "movie_pairs_with_similarity.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLq1X3DSwvZq",
        "outputId": "1184bfa1-c307-4751-98fa-8e6fe3f22672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------+--------------------+\n",
            "|movieId|movieId2|similarity          |\n",
            "+-------+--------+--------------------+\n",
            "|1      |2       |0.007491789327389531|\n",
            "|1      |3       |0.009125266483879567|\n",
            "|1      |4       |0.0                 |\n",
            "|1      |5       |0.0                 |\n",
            "|1      |6       |0.007502872148281604|\n",
            "|1      |7       |0.0                 |\n",
            "|1      |8       |0.0                 |\n",
            "|1      |9       |0.0                 |\n",
            "|1      |10      |0.003378346915809851|\n",
            "|1      |11      |0.0                 |\n",
            "|1      |12      |0.0                 |\n",
            "|1      |13      |0.0                 |\n",
            "|1      |14      |0.0                 |\n",
            "|1      |15      |0.0                 |\n",
            "|1      |16      |0.008549380611425152|\n",
            "|1      |17      |0.0                 |\n",
            "|1      |18      |0.0                 |\n",
            "|1      |19      |0.0                 |\n",
            "|1      |20      |0.0                 |\n",
            "|1      |21      |0.0                 |\n",
            "+-------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, movieId2: int, similarity: double]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns_to_drop = [\"user_rating\", \"user_rating2\"]\n",
        "\n",
        "# Drop the specified columns\n",
        "movie_pairs_with_similarity = movie_pairs_with_similarity.drop(*columns_to_drop)\n",
        "\n",
        "# Show the modified DataFrame\n",
        "movie_pairs_with_similarity.show(truncate=False)\n",
        "\n",
        "movie_pairs_with_similarity.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "KY0JmJ57pu9h",
        "outputId": "ca61a0f7-fe8d-4c71-9f0f-48908d9dc41a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b0a986bd0cdc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindowSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"similarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add a rank column based on the similarity within each partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, row_number\n",
        "from pyspark.sql import Window\n",
        "windowSpec = Window.partitionBy(\"movieId\").orderBy(col(\"similarity\").desc())\n",
        "\n",
        "# Add a rank column based on the similarity within each partition\n",
        "ranked_data = movie_pairs_with_similarity.withColumn(\"rank\", row_number().over(windowSpec))\n",
        "\n",
        "# Filter only the top 5 rows for each 'movieId'\n",
        "top5_similarities = ranked_data.filter(col(\"rank\") <= 5).drop(\"rank\")\n",
        "\n",
        "# Show the result\n",
        "top5_similarities.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPoRWTSVqAtw"
      },
      "outputs": [],
      "source": [
        "top5_similarities.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgwLZN30qE1S"
      },
      "outputs": [],
      "source": [
        "test_data_joined_similarity = (\n",
        "    test_data.join(top5_similarities, on=test_data.movieId == top5_similarities.movieId, how='left')\n",
        "    .select(\n",
        "        test_data[\"movieId\"].alias(\"movieId_1\"),\n",
        "        top5_similarities[\"movieId2\"].alias(\"movieId_2\"),\n",
        "        test_data[\"userId\"].alias(\"user_Id\"),\n",
        "        top5_similarities[\"similarity\"].alias(\"similarity\"),\n",
        "        test_data[\"rating\"].alias(\"rating\")\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Show the result\n",
        "test_data_joined_similarity.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQeQXwEaqcUt"
      },
      "outputs": [],
      "source": [
        "train_data_joined = (\n",
        "    test_data_joined_similarity.alias(\"test_data\")\n",
        "    .join(train_data.alias(\"train_data\"), on=((col(\"test_data.movieId_2\") == col(\"train_data.movieId\")) & (col(\"test_data.user_Id\") == col(\"train_data.userId\"))), how='left')\n",
        "    .select(\n",
        "        col(\"test_data.movieId_1\").alias(\"f_movieId\"),\n",
        "        col(\"test_data.movieId_2\").alias(\"f_movieId2\"),\n",
        "        col(\"test_data.user_Id\").alias(\"f_userId\"),\n",
        "        col(\"test_data.similarity\").alias(\"similarity\"),\n",
        "        col(\"test_data.rating\").alias(\"true_rating\"),\n",
        "        col(\"train_data.rating\").alias(\"rating\")\n",
        "    )\n",
        ")\n",
        "\n",
        "train_data_joined.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xpuBx-Fr6-p"
      },
      "outputs": [],
      "source": [
        "train_data_joined.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m2fLRA-qeGw"
      },
      "outputs": [],
      "source": [
        "result_not_null = train_data_joined.filter(col(\"rating\").isNotNull())\n",
        "\n",
        "# Show the result where 'rating' is not null\n",
        "result_not_null.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkJSwihcqhWD"
      },
      "outputs": [],
      "source": [
        "result_grouped_weighted = (\n",
        "    train_data_joined\n",
        "    .groupBy(\"f_movieId\")\n",
        "    .agg(\n",
        "        F.sum((F.col(\"similarity\") * F.col(\"rating\"))).alias(\"weighted_sum_ratings\"),\n",
        "        F.sum(\"similarity\").alias(\"sum_similarity\"),\n",
        "        F.first(\"true_rating\").alias(\"true_rating\")\n",
        "    ).withColumn(\"prediction\", F.col(\"weighted_sum_ratings\") / F.col(\"sum_similarity\"))\n",
        ")\n",
        "\n",
        "result_grouped_weighted.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn4ajYLoSnNI"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"true_rating\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(result_grouped_weighted)\n",
        "print(f\"Root Mean Squared Error for Item-Item CF (RMSE): {rmse}\")\n",
        "\n",
        "evaluator_mse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"true_rating\", metricName=\"mse\")\n",
        "mse = evaluator_mse.evaluate(result_grouped_weighted)\n",
        "print(f\"Mean Squared Errorfor Item-Item CF (MSE): {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFRJknTT4C5Q",
        "outputId": "abd04647-26ff-4da4-a6a9-48a9e60150aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------------------------+-------------------------------------------+\n",
            "|movieId|title                                |genres                                     |\n",
            "+-------+-------------------------------------+-------------------------------------------+\n",
            "|1      |Toy Story (1995)                     |Adventure|Animation|Children|Comedy|Fantasy|\n",
            "|2      |Jumanji (1995)                       |Adventure|Children|Fantasy                 |\n",
            "|3      |Grumpier Old Men (1995)              |Comedy|Romance                             |\n",
            "|4      |Waiting to Exhale (1995)             |Comedy|Drama|Romance                       |\n",
            "|5      |Father of the Bride Part II (1995)   |Comedy                                     |\n",
            "|6      |Heat (1995)                          |Action|Crime|Thriller                      |\n",
            "|7      |Sabrina (1995)                       |Comedy|Romance                             |\n",
            "|8      |Tom and Huck (1995)                  |Adventure|Children                         |\n",
            "|9      |Sudden Death (1995)                  |Action                                     |\n",
            "|10     |GoldenEye (1995)                     |Action|Adventure|Thriller                  |\n",
            "|11     |American President, The (1995)       |Comedy|Drama|Romance                       |\n",
            "|12     |Dracula: Dead and Loving It (1995)   |Comedy|Horror                              |\n",
            "|13     |Balto (1995)                         |Adventure|Animation|Children               |\n",
            "|14     |Nixon (1995)                         |Drama                                      |\n",
            "|15     |Cutthroat Island (1995)              |Action|Adventure|Romance                   |\n",
            "|16     |Casino (1995)                        |Crime|Drama                                |\n",
            "|17     |Sense and Sensibility (1995)         |Drama|Romance                              |\n",
            "|18     |Four Rooms (1995)                    |Comedy                                     |\n",
            "|19     |Ace Ventura: When Nature Calls (1995)|Comedy                                     |\n",
            "|20     |Money Train (1995)                   |Action|Comedy|Crime|Drama|Thriller         |\n",
            "+-------+-------------------------------------+-------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "movies = spark.read.csv(\"/content/drive/MyDrive/movies.csv\", header=True, inferSchema=True)\n",
        "\n",
        "movies.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQoXBLPH-MVo"
      },
      "outputs": [],
      "source": [
        "lr_data = (\n",
        "    sampled_ratings.alias(\"rdata\")\n",
        "    .join(movies.alias(\"mdata\"), on=(col(\"rdata.movieId\") == col(\"mdata.movieId\")), how='left')\n",
        "    .select(\n",
        "        col(\"rdata.movieId\").alias(\"f_movieId\"),\n",
        "        col(\"mdata.title\").alias(\"title\"),\n",
        "        col(\"rdata.userId\").alias(\"f_userId\"),\n",
        "        col(\"mdata.genres\").alias(\"genres\"),\n",
        "        col(\"rdata.rating\").alias(\"rating\")\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuibvucVGsZl",
        "outputId": "c22df120-b4e9-4d76-9938-26725af2a8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+--------+--------------------+------+\n",
            "|f_movieId|               title|f_userId|              genres|rating|\n",
            "+---------+--------------------+--------+--------------------+------+\n",
            "|    53953|         1408 (2007)|      61|Drama|Horror|Thri...|   2.0|\n",
            "|      590|Dances with Wolve...|      64|Adventure|Drama|W...|   5.0|\n",
            "|      432|City Slickers II:...|      68|Adventure|Comedy|...|   3.0|\n",
            "|     2739|Color Purple, The...|      73|               Drama|   2.0|\n",
            "|    86880|Pirates of the Ca...|      82|Action|Adventure|...|   2.0|\n",
            "|     5502|        Signs (2002)|      90|Horror|Sci-Fi|Thr...|   3.5|\n",
            "|     1380|       Grease (1978)|      91|Comedy|Musical|Ro...|   4.0|\n",
            "|   103042| Man of Steel (2013)|      96|Action|Adventure|...|   2.0|\n",
            "|     1210|Star Wars: Episod...|     100|Action|Adventure|...|   4.0|\n",
            "|      885|        Bogus (1996)|     104|Children|Drama|Fa...|   1.0|\n",
            "|       78|Crossing Guard, T...|     114|Action|Crime|Dram...|   4.0|\n",
            "|      484|       Lassie (1994)|     116|  Adventure|Children|   1.0|\n",
            "|      539|Sleepless in Seat...|     124|Comedy|Drama|Romance|   3.5|\n",
            "|     3175| Galaxy Quest (1999)|     124|Adventure|Comedy|...|   3.0|\n",
            "|       36|Dead Man Walking ...|     126|         Crime|Drama|   3.0|\n",
            "|    46970|Talladega Nights:...|     129|       Action|Comedy|   2.0|\n",
            "|     5902|   Adaptation (2002)|     132|Comedy|Drama|Romance|   4.5|\n",
            "|      344|Ace Ventura: Pet ...|     135|              Comedy|   0.5|\n",
            "|     1073|Willy Wonka & the...|     137|Children|Comedy|F...|   4.0|\n",
            "|     1997|Exorcist, The (1973)|     137|      Horror|Mystery|   4.0|\n",
            "+---------+--------------------+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kptwkr2eI2aj"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer,IDF, HashingTF\n",
        "\n",
        "\n",
        "tokenizer_genres = Tokenizer(inputCol=\"genres\", outputCol=\"genres_tokens\")\n",
        "lr_data = tokenizer_genres.transform(lr_data)\n",
        "\n",
        "# Apply HashingTF on 'genres_tokens'\n",
        "hashingTF_genres = HashingTF(inputCol=\"genres_tokens\", outputCol=\"rawFeatures_genres\", numFeatures=20)\n",
        "hashing_df = hashingTF_genres.transform(lr_data)\n",
        "\n",
        "# Apply IDF on 'rawFeatures_genres'\n",
        "idf_genres = IDF(inputCol=\"rawFeatures_genres\", outputCol=\"features_genres\")\n",
        "idfModel_genres = idf_genres.fit(hashing_df)\n",
        "vectorized_df = idfModel_genres.transform(hashing_df)\n",
        "\n",
        "# Similarly, you can apply the same process for the 'title' column\n",
        "tokenizer_title = Tokenizer(inputCol=\"title\", outputCol=\"title_tokens\")\n",
        "vectorized_df = tokenizer_title.transform(vectorized_df)\n",
        "\n",
        "hashingTF_title = HashingTF(inputCol=\"title_tokens\", outputCol=\"rawFeatures_title\", numFeatures=20)\n",
        "hashing_df = hashingTF_title.transform(vectorized_df)\n",
        "\n",
        "idf_title = IDF(inputCol=\"rawFeatures_title\", outputCol=\"features_title\")\n",
        "idfModel_title = idf_title.fit(hashing_df)\n",
        "vectorized_df = idfModel_title.transform(hashing_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgODLB3qKNS0",
        "outputId": "2548c2f7-026d-404c-dffe-53a58875e609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|f_movieId|               title|f_userId|              genres|rating|       genres_tokens|rawFeatures_genres|     features_genres|        title_tokens|   rawFeatures_title|      features_title|   combined_features|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    53953|         1408 (2007)|      61|Drama|Horror|Thri...|   2.0|[drama|horror|thr...|   (20,[19],[1.0])|(20,[19],[3.76304...|      [1408, (2007)]|(20,[7,19],[1.0,1...|(20,[7,19],[1.809...|(40,[19,27,39],[3...|\n",
            "|      590|Dances with Wolve...|      64|Adventure|Drama|W...|   5.0|[adventure|drama|...|    (20,[2],[1.0])|(20,[2],[3.264279...|[dances, with, wo...|(20,[0,7,10,13],[...|(20,[0,7,10,13],[...|(40,[2,20,27,30,3...|\n",
            "|      432|City Slickers II:...|      68|Adventure|Comedy|...|   3.0|[adventure|comedy...|    (20,[7],[1.0])|(20,[7],[2.964319...|[city, slickers, ...|(20,[1,3,8,13,15,...|(20,[1,3,8,13,15,...|(40,[7,21,23,28,3...|\n",
            "|     2739|Color Purple, The...|      73|               Drama|   2.0|             [drama]|    (20,[4],[1.0])|(20,[4],[2.181835...|[color, purple,, ...|(20,[1,11,12,17],...|(20,[1,11,12,17],...|(40,[4,21,31,32,3...|\n",
            "|    86880|Pirates of the Ca...|      82|Action|Adventure|...|   2.0|[action|adventure...|   (20,[10],[1.0])|(20,[10],[3.90055...|[pirates, of, the...|(20,[0,2,4,5,15,1...|(20,[0,2,4,5,15,1...|(40,[10,20,22,24,...|\n",
            "|     5502|        Signs (2002)|      90|Horror|Sci-Fi|Thr...|   3.5|[horror|sci-fi|th...|   (20,[13],[1.0])|(20,[13],[3.51410...|     [signs, (2002)]|(20,[11,17],[1.0,...|(20,[11,17],[1.54...|(40,[13,31,37],[3...|\n",
            "|     1380|       Grease (1978)|      91|Comedy|Musical|Ro...|   4.0|[comedy|musical|r...|    (20,[7],[1.0])|(20,[7],[2.964319...|    [grease, (1978)]|(20,[1,4],[1.0,1.0])|(20,[1,4],[1.8235...|(40,[7,21,24],[2....|\n",
            "|   103042| Man of Steel (2013)|      96|Action|Adventure|...|   2.0|[action|adventure...|    (20,[9],[1.0])|(20,[9],[2.815135...|[man, of, steel, ...|(20,[0,1,9,15],[1...|(20,[0,1,9,15],[2...|(40,[9,20,21,29,3...|\n",
            "|     1210|Star Wars: Episod...|     100|Action|Adventure|...|   4.0|[action|adventure...|    (20,[8],[1.0])|(20,[8],[2.815135...|[star, wars:, epi...|(20,[5,9,10,12,15...|(20,[5,9,10,12,15...|(40,[8,25,29,30,3...|\n",
            "|      885|        Bogus (1996)|     104|Children|Drama|Fa...|   1.0|[children|drama|f...|   (20,[16],[1.0])|(20,[16],[2.30846...|     [bogus, (1996)]|(20,[3,6],[1.0,1.0])|(20,[3,6],[1.3144...|(40,[16,23,26],[2...|\n",
            "|       78|Crossing Guard, T...|     114|Action|Crime|Dram...|   4.0|[action|crime|dra...|    (20,[3],[1.0])|(20,[3],[2.586199...|[crossing, guard,...|(20,[8,13,17],[1....|(20,[8,13,17],[1....|(40,[3,28,33,37],...|\n",
            "|      484|       Lassie (1994)|     116|  Adventure|Children|   1.0|[adventure|children]|    (20,[2],[1.0])|(20,[2],[3.264279...|    [lassie, (1994)]|(20,[3,5],[1.0,1.0])|(20,[3,5],[1.3144...|(40,[2,23,25],[3....|\n",
            "|      539|Sleepless in Seat...|     124|Comedy|Drama|Romance|   3.5|[comedy|drama|rom...|   (20,[12],[1.0])|(20,[12],[2.06591...|[sleepless, in, s...|(20,[1,3,11],[2.0...|(20,[1,3,11],[3.6...|(40,[12,21,23,31]...|\n",
            "|     3175| Galaxy Quest (1999)|     124|Adventure|Comedy|...|   3.0|[adventure|comedy...|   (20,[19],[1.0])|(20,[19],[3.76304...|[galaxy, quest, (...|(20,[15,18],[1.0,...|(20,[15,18],[1.58...|(40,[19,35,38],[3...|\n",
            "|       36|Dead Man Walking ...|     126|         Crime|Drama|   3.0|       [crime|drama]|   (20,[16],[1.0])|(20,[16],[2.30846...|[dead, man, walki...|(20,[9,13,15,17],...|(20,[9,13,15,17],...|(40,[16,29,33,35,...|\n",
            "|    46970|Talladega Nights:...|     129|       Action|Comedy|   2.0|     [action|comedy]|    (20,[7],[1.0])|(20,[7],[2.964319...|[talladega, night...|(20,[6,8,10,11,15...|(20,[6,8,10,11,15...|(40,[7,26,28,30,3...|\n",
            "|     5902|   Adaptation (2002)|     132|Comedy|Drama|Romance|   4.5|[comedy|drama|rom...|   (20,[12],[1.0])|(20,[12],[2.06591...|[adaptation, (2002)]|(20,[14,17],[1.0,...|(20,[14,17],[2.01...|(40,[12,34,37],[2...|\n",
            "|      344|Ace Ventura: Pet ...|     135|              Comedy|   0.5|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[ace, ventura:, p...|(20,[3,5,8,11,14]...|(20,[3,5,8,11,14]...|(40,[12,23,25,28,...|\n",
            "|     1073|Willy Wonka & the...|     137|Children|Comedy|F...|   4.0|[children|comedy|...|   (20,[10],[1.0])|(20,[10],[3.90055...|[willy, wonka, &,...|(20,[6,8,12,16,17...|(20,[6,8,12,16,17...|(40,[10,26,28,32,...|\n",
            "|     1997|Exorcist, The (1973)|     137|      Horror|Mystery|   4.0|    [horror|mystery]|   (20,[15],[1.0])|(20,[15],[3.21110...|[exorcist,, the, ...|(20,[5,8,17],[1.0...|(20,[5,8,17],[1.9...|(40,[15,25,28,37]...|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[f_movieId: int, title: string, f_userId: int, genres: string, rating: double, genres_tokens: array<string>, rawFeatures_genres: vector, features_genres: vector, title_tokens: array<string>, rawFeatures_title: vector, features_title: vector, combined_features: vector]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Assuming you have two feature columns: \"features_genres\" and \"features_title\"\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"features_genres\", \"features_title\"],\n",
        "    outputCol=\"combined_features\"\n",
        ")\n",
        "\n",
        "# Assuming 'lr_data' is your DataFrame with features\n",
        "vectorized_df = assembler.transform(vectorized_df)\n",
        "\n",
        "vectorized_df.show()\n",
        "vectorized_df.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9v6j8ucMYQ7",
        "outputId": "674d2812-3bb2-45e8-92a8-a95b34ad35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|f_movieId|               title|f_userId|              genres|rating|       genres_tokens|rawFeatures_genres|     features_genres|        title_tokens|   rawFeatures_title|      features_title|   combined_features|        prediction|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|        1|    Toy Story (1995)|    1836|Adventure|Animati...|   5.0|[adventure|animat...|   (20,[16],[1.0])|(20,[16],[2.30846...|[toy, story, (1995)]|(20,[15,17],[1.0,...|(20,[15,17],[1.58...|(40,[16,35,37],[2...| 3.524008858736442|\n",
            "|        1|    Toy Story (1995)|    8636|Adventure|Animati...|   3.5|[adventure|animat...|   (20,[16],[1.0])|(20,[16],[2.30846...|[toy, story, (1995)]|(20,[15,17],[1.0,...|(20,[15,17],[1.58...|(40,[16,35,37],[2...| 3.524008858736442|\n",
            "|        5|Father of the Bri...|   17430|              Comedy|   3.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[father, of, the,...|(20,[0,3,9,15,17]...|(20,[0,3,9,15,17]...|(40,[12,20,23,29,...| 3.306468571537864|\n",
            "|        5|Father of the Bri...|   26657|              Comedy|   1.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[father, of, the,...|(20,[0,3,9,15,17]...|(20,[0,3,9,15,17]...|(40,[12,20,23,29,...| 3.306468571537864|\n",
            "|        6|         Heat (1995)|   26149|Action|Crime|Thri...|   1.0|[action|crime|thr...|   (20,[14],[1.0])|(20,[14],[3.01368...|      [heat, (1995)]|(20,[7,17],[1.0,1...|(20,[7,17],[1.809...|(40,[14,27,37],[3...|3.5705978305721047|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "\n",
        "(train_data, test_data) = vectorized_df.randomSplit([0.8, 0.2], seed=1234)\n",
        "train_data.cache()\n",
        "test_data.cache()\n",
        "\n",
        "# Defining the Linear Regression Model\n",
        "lr = LinearRegression(\n",
        "    featuresCol=\"combined_features\",\n",
        "    labelCol=\"rating\"\n",
        ")\n",
        "\n",
        "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 1.0]).build()\n",
        "\n",
        "crossval = CrossValidator(estimator=lr,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\"),\n",
        "                          numFolds=10)\n",
        "\n",
        "lrModel = crossval.fit(train_data)\n",
        "\n",
        "bestModel = lrModel.bestModel\n",
        "\n",
        "predictions = bestModel.transform(test_data)\n",
        "predictions.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SOW5tu3ltX9",
        "outputId": "23b38aee-1567-42b6-e7d3-eb827d6e998c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|f_movieId|               title|f_userId|              genres|rating|       genres_tokens|rawFeatures_genres|     features_genres|        title_tokens|   rawFeatures_title|      features_title|   combined_features|        prediction|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|        1|    Toy Story (1995)|    1836|Adventure|Animati...|   5.0|[adventure|animat...|   (20,[16],[1.0])|(20,[16],[2.30846...|[toy, story, (1995)]|(20,[15,17],[1.0,...|(20,[15,17],[1.58...|(40,[16,35,37],[2...| 3.524008858736442|\n",
            "|        1|    Toy Story (1995)|    8636|Adventure|Animati...|   3.5|[adventure|animat...|   (20,[16],[1.0])|(20,[16],[2.30846...|[toy, story, (1995)]|(20,[15,17],[1.0,...|(20,[15,17],[1.58...|(40,[16,35,37],[2...| 3.524008858736442|\n",
            "|        5|Father of the Bri...|   17430|              Comedy|   3.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[father, of, the,...|(20,[0,3,9,15,17]...|(20,[0,3,9,15,17]...|(40,[12,20,23,29,...| 3.306468571537864|\n",
            "|        5|Father of the Bri...|   26657|              Comedy|   1.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[father, of, the,...|(20,[0,3,9,15,17]...|(20,[0,3,9,15,17]...|(40,[12,20,23,29,...| 3.306468571537864|\n",
            "|        6|         Heat (1995)|   26149|Action|Crime|Thri...|   1.0|[action|crime|thr...|   (20,[14],[1.0])|(20,[14],[3.01368...|      [heat, (1995)]|(20,[7,17],[1.0,1...|(20,[7,17],[1.809...|(40,[14,27,37],[3...|3.5705978305721047|\n",
            "|        6|         Heat (1995)|   26198|Action|Crime|Thri...|   3.0|[action|crime|thr...|   (20,[14],[1.0])|(20,[14],[3.01368...|      [heat, (1995)]|(20,[7,17],[1.0,1...|(20,[7,17],[1.809...|(40,[14,27,37],[3...|3.5705978305721047|\n",
            "|        6|         Heat (1995)|   26400|Action|Crime|Thri...|   5.0|[action|crime|thr...|   (20,[14],[1.0])|(20,[14],[3.01368...|      [heat, (1995)]|(20,[7,17],[1.0,1...|(20,[7,17],[1.809...|(40,[14,27,37],[3...|3.5705978305721047|\n",
            "|       11|American Presiden...|   10925|Comedy|Drama|Romance|   5.0|[comedy|drama|rom...|   (20,[12],[1.0])|(20,[12],[2.06591...|[american, presid...|(20,[6,12,17],[1....|(20,[6,12,17],[1....|(40,[12,26,32,37]...|3.3871784946896817|\n",
            "|       17|Sense and Sensibi...|     264|       Drama|Romance|   3.0|     [drama|romance]|    (20,[3],[1.0])|(20,[3],[2.586199...|[sense, and, sens...|(20,[6,7,11,17],[...|(20,[6,7,11,17],[...|(40,[3,26,27,31,3...|3.6197906311464396|\n",
            "|       17|Sense and Sensibi...|    3508|       Drama|Romance|   3.0|     [drama|romance]|    (20,[3],[1.0])|(20,[3],[2.586199...|[sense, and, sens...|(20,[6,7,11,17],[...|(20,[6,7,11,17],[...|(40,[3,26,27,31,3...|3.6197906311464396|\n",
            "|       17|Sense and Sensibi...|   22241|       Drama|Romance|   5.0|     [drama|romance]|    (20,[3],[1.0])|(20,[3],[2.586199...|[sense, and, sens...|(20,[6,7,11,17],[...|(20,[6,7,11,17],[...|(40,[3,26,27,31,3...|3.6197906311464396|\n",
            "|       19|Ace Ventura: When...|   15095|              Comedy|   2.5|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[ace, ventura:, w...|(20,[11,14,16,17,...|(20,[11,14,16,17,...|(40,[12,31,34,36,...|3.4822635799862196|\n",
            "|       19|Ace Ventura: When...|   20347|              Comedy|   2.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[ace, ventura:, w...|(20,[11,14,16,17,...|(20,[11,14,16,17,...|(40,[12,31,34,36,...|3.4822635799862196|\n",
            "|       19|Ace Ventura: When...|   21129|              Comedy|   4.0|            [comedy]|   (20,[12],[1.0])|(20,[12],[2.06591...|[ace, ventura:, w...|(20,[11,14,16,17,...|(20,[11,14,16,17,...|(40,[12,31,34,36,...|3.4822635799862196|\n",
            "|       21|   Get Shorty (1995)|    9552|Comedy|Crime|Thri...|   4.0|[comedy|crime|thr...|    (20,[0],[1.0])|(20,[0],[4.089287...|[get, shorty, (19...|(20,[6,9,17],[1.0...|(20,[6,9,17],[1.6...|(40,[0,26,29,37],...|3.5757794212439142|\n",
            "|       22|      Copycat (1995)|     328|Crime|Drama|Horro...|   3.0|[crime|drama|horr...|    (20,[0],[1.0])|(20,[0],[4.089287...|   [copycat, (1995)]|(20,[13,17],[1.0,...|(20,[13,17],[2.01...|(40,[0,33,37],[4....| 3.569671550909915|\n",
            "|       25|Leaving Las Vegas...|   12420|       Drama|Romance|   3.0|     [drama|romance]|    (20,[3],[1.0])|(20,[3],[2.586199...|[leaving, las, ve...|(20,[2,13,14,17],...|(20,[2,13,14,17],...|(40,[3,22,33,34,3...| 3.605715580430053|\n",
            "|       25|Leaving Las Vegas...|   12504|       Drama|Romance|   3.0|     [drama|romance]|    (20,[3],[1.0])|(20,[3],[2.586199...|[leaving, las, ve...|(20,[2,13,14,17],...|(20,[2,13,14,17],...|(40,[3,22,33,34,3...| 3.605715580430053|\n",
            "|       26|      Othello (1995)|    2518|               Drama|   3.0|             [drama]|    (20,[4],[1.0])|(20,[4],[2.181835...|   [othello, (1995)]|(20,[12,17],[1.0,...|(20,[12,17],[1.99...|(40,[4,32,37],[2....| 3.556303936151887|\n",
            "|       32|Twelve Monkeys (a...|    6532|Mystery|Sci-Fi|Th...|   3.0|[mystery|sci-fi|t...|    (20,[0],[1.0])|(20,[0],[4.089287...|[twelve, monkeys,...|(20,[3,4,5,14,17]...|(20,[3,4,5,14,17]...|(40,[0,23,24,25,3...|3.6136752447801443|\n",
            "+---------+--------------------+--------+--------------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrPVb2SURbDf",
        "outputId": "1e110c22-3764-425d-b698-662f86b1738a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error for Linear Regression (RMSE): 1.058988643036256\n",
            "Mean Squared Error for Linear Regression (MSE): 1.121456946079771\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error for Linear Regression (RMSE): {rmse}\")\n",
        "\n",
        "evaluator_mse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"mse\")\n",
        "mse = evaluator_mse.evaluate(predictions)\n",
        "print(f\"Mean Squared Error for Linear Regression (MSE): {mse}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}